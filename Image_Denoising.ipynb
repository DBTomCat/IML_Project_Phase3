{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div align=center>\n",
        "\t\t\n",
        "<p></p>\n",
        "<p></p>\n",
        "<font size=5>\n",
        "In the Name of God\n",
        "<font/>\n",
        "<p></p>\n",
        " <br/>\n",
        "    <br/>\n",
        "<font color=#4d7db8>\n",
        "Sharif University of Technology - Department of Electrical Engineering\n",
        "</font>\n",
        "<p></p>\n",
        "<font color=#4d7db8>\n",
        "Introduction To Machine Learning - Dr. Sajjad Amini\n",
        "</font>\n",
        "<br/>\n",
        "<br/>\n",
        "Spring Semester 1401-02\n",
        "\n",
        "<div/>\n",
        "\n",
        "<hr/>\n",
        "\t\t<div align=center>\n",
        "\t\t    <font color=red size=6>\n",
        "\t\t\t    <br />\n",
        "Project - 3rd Phase\n",
        "<br />\n",
        "Image Denoising using Autoencoder and PCA\n",
        "\t\t\t</font>\n",
        "    <br/>\n",
        "<font size=4>\n",
        "\t\t\t<br/><br/>\n",
        "Due on Tir 10th\n",
        "                <br/><b>\n",
        "              Cheating is Strongly Prohibited\n",
        "                </b><br/><br/>\n",
        "                <font color=green>\n",
        "Should you have any questions concerning the project, please feel free to ask via Telegram.\n",
        "     </font>\n",
        "</font>\n",
        "                <br/>\n",
        "    </div>"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Personal Info\n",
        "<hr/>\n",
        "    <div class=\"column\" align=center>\n",
        "    <font size=4>\n",
        "        <div class=\"column\">\n",
        "        <br />\n",
        "            student_number = 99105901\n",
        "            <br />\n",
        "            Name = Amirhossein\n",
        "            <br />\n",
        "            Last_Name = Akbari\n",
        "        </div>\n",
        "        <div class=\"column\">\n",
        "        <br />\n",
        "            student_number = 99106255\n",
        "            <br />\n",
        "            Name = Alireza  \n",
        "            <br />\n",
        "            Last_Name = Shokrani\n",
        "        </div>\n",
        "    </font>\n",
        "    </div>\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "UpqOZ2JemP0B",
        "tags": []
      },
      "source": [
        "1. Download the MNIST dataset and create a dataloader that adds gaussian noise to the input images.\n",
        "2. Design and train an AutoEncoder on the MNIST dataset to denoise the noisy images.\n",
        "3. Visualize original images, their corresponding noisy images and their reconstructed versions side by side.\n",
        "4. Repeat the previous steps using PCA algorithm."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Import Necessary Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.decomposition import PCA"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Load Dataset and Prepare It"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "# Define the transformations\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "# Download and load the MNIST dataset\n",
        "train_dataset = datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
        "test_dataset = datasets.MNIST(root='./data', train=False, transform=transform)\n",
        "\n",
        "# Create data loaders\n",
        "batch_size = 64\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": []
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Define Your Model\n",
        "torch neural network model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "class Autoencoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Autoencoder, self).__init__()\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Linear(784, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 64),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(64, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 784),\n",
        "            nn.Sigmoid(),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(x.size(0), -1)\n",
        "        encoded = self.encoder(x)\n",
        "        decoded = self.decoder(encoded)\n",
        "        decoded = decoded.view(decoded.size(0), 1, 28, 28)\n",
        "        return encoded, decoded\n",
        "\n",
        "# Create an instance of the Autoencoder model\n",
        "autoencoder = Autoencoder()\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Fit The Model\n",
        "Also Define optimizer, Criterion and other parameters "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "# Define the optimizer, criterion, and other parameters\n",
        "lr = 0.001\n",
        "num_epochs = 10\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(autoencoder.parameters(), lr=lr)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(num_epochs):\n",
        "    for batch_idx, (data, _) in enumerate(train_loader):\n",
        "        # Add Gaussian noise to the input images\n",
        "        noisy_data = data + torch.randn(data.size()) * 0.1\n",
        "\n",
        "        # Zero the gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        _, output = autoencoder(noisy_data)\n",
        "\n",
        "        # Calculate the loss\n",
        "        loss = criterion(output, data)\n",
        "\n",
        "        # Backward pass\n",
        "        loss.backward()\n",
        "\n",
        "        # Update the weights\n",
        "        optimizer.step()\n",
        "\n",
        "        # Print the progress\n",
        "        if (batch_idx + 1) % 100 == 0:\n",
        "            print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'\n",
        "                  .format(epoch + 1, num_epochs, batch_idx + 1, len(train_loader), loss.item()))\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Plot The Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "# Visualize original images, noisy images, and reconstructed images\n",
        "num_images = 10\n",
        "images, _ = iter(test_loader).next()\n",
        "noisy_images = images + torch.randn(images.size()) * 0.1\n",
        "encoded_images, denoised_images = autoencoder(noisy_images)\n",
        "\n",
        "# Convert images to numpy arrays\n",
        "images = images.numpy()\n",
        "noisy_images = noisy_images.numpy()\n",
        "denoised_images = denoised_images.detach().numpy()\n",
        "\n",
        "# Plot the images\n",
        "fig, axes = plt.subplots(nrows=3, ncols=num_images, figsize=(10, 6))\n",
        "\n",
        "for i in range(num_images):\n",
        "    axes[0, i].imshow(np.squeeze(images[i]), cmap='gray')\n",
        "    axes[0, i].axis('off')\n",
        "    axes[0, i].set_title('Original')\n",
        "\n",
        "    axes[1, i].imshow(np.squeeze(noisy_images[i]), cmap='gray')\n",
        "    axes[1, i].axis('off')\n",
        "    axes[1, i].set_title('Noisy')\n",
        "\n",
        "    axes[2, i].imshow(np.squeeze(denoised_images[i]), cmap='gray')\n",
        "    axes[2, i].axis('off')\n",
        "    axes[2, i].set_title('Denoised')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# PCA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "# Flatten the images\n",
        "flatten_images = train_dataset.data.reshape(train_dataset.data.shape[0], -1).numpy()\n",
        "\n",
        "# Perform PCA\n",
        "pca = PCA(n_components=64)\n",
        "pca_images = pca.fit_transform(flatten_images)\n",
        "\n",
        "# Reconstruct the images\n",
        "reconstructed_images = pca.inverse_transform(pca_images)\n",
        "\n",
        "# Reshape the images\n",
        "reconstructed_images = reconstructed_images.reshape(-1, 1, 28, 28)\n",
        "\n",
        "# Plot the images\n",
        "fig, axes = plt.subplots(nrows=2, ncols=num_images, figsize=(10, 4))\n",
        "\n",
        "for i in range(num_images):\n",
        "    axes[0, i].imshow(np.squeeze(images[i]), cmap='gray')\n",
        "    axes[0, i].axis('off')\n",
        "    axes[0, i].set_title('Original')\n",
        "\n",
        "    axes[1, i].imshow(np.squeeze(reconstructed_images[i]), cmap='gray')\n",
        "    axes[1, i].axis('off')\n",
        "    axes[1, i].set_title('Reconstructed')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
